# SeeForAll ğŸ‘ï¸â€ğŸ—¨ï¸  
### Real-Time AI Vision Assistant for the Visually Impaired

SeeForAll is a real-time computer visionâ€“based assistive system that detects objects using **YOLOv8** and provides **audio narration** describing what is present in front of the user.  
The project is designed to help visually impaired users understand their surroundings through spoken feedback.

---

## ğŸš€ Project Motivation

Visually impaired individuals often face difficulty identifying obstacles, people, and objects around them.  
SeeForAll bridges this gap by combining **AI-based object detection** with **text-to-speech narration**, enabling users to hear what the camera sees in real time.

---

## âœ¨ Key Features

- ğŸ” Real-time object detection using YOLOv8  
- ğŸ”Š Voice narration of detected objects  
- ğŸ§­ Direction awareness (left / ahead / right)  
- ğŸ“ Distance estimation (far / near / very close)  
- ğŸ§  Smart narration control to avoid repeated speech  
- ğŸ–¥ï¸ Live detection window for visual feedback  

---

## ğŸ› ï¸ Technologies Used

- Python 3.10  
- YOLOv8 (Ultralytics)  
- OpenCV  
- PyTorch  
- PyTTSx3 (offline text-to-speech)  
- Multithreading & Queues  

---

## âš™ï¸ How It Works

1. The webcam captures live video frames  
2. YOLOv8 detects objects in each frame  
3. For each detected object:
   - Position is calculated (left / ahead / right)
   - Distance is estimated using bounding box size  
4. A narration message is generated  
5. The system speaks the detected objects in real time  

---

## ğŸ“‚ Project Structure

SeeForAll/
â”‚
â”œâ”€â”€ see_for_all.py # Main application code
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ .gitignore # Ignored files & folders

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/abPragathi007/SeeForAll.git
cd SeeForAll
2ï¸âƒ£ Create a virtual environment
python -m venv venv

3ï¸âƒ£ Activate the virtual environment

-->Windows
venv\Scripts\activate

--> Linux / macOS
source venv/bin/activate
4ï¸âƒ£ Install dependencies
pip install -r requirements.txt

5ï¸âƒ£ Run the application
python see_for_all.py


Press Q to quit the application.

âš ï¸ Important Notes

A working webcam is required

Speakers or headphones are required for narration

This project runs only on a local system

It does not run on GitHub Pages or Codespaces

YOLO model weights download automatically on first run

ğŸ§ª Limitations

Distance estimation is approximate

Performance depends on lighting conditions

Requires a system with camera and audio support
ğŸ”® Future Enhancements

ğŸš¦ Obstacle danger alerts for very close objects

ğŸ¤ Voice commands (mute / resume narration)

ğŸ“± Mobile camera support (IP webcam)

ğŸŒ Web-based version for image/video uploads

ğŸ§­ Navigation and path guidance

ğŸ‘©â€ğŸ’» Author

Pragathi
AI & Computer Vision Enthusiast

ğŸ“œ License

This project is open-source and available under the MIT License.


---

## âœ… After pasting this (FINAL STEP)

Run these commands:

```powershell
git add README.md
git commit -m "Add complete project documentation"
git push